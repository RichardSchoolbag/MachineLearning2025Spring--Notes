### 01 课程概论——生成式人工智能技术突破与未来发展
***
### 目录
- [1.有什么样的行为](#1有什么样的行为)
  - [1.1过去生成式ai用处及特点](#11过去生成式ai用处及特点)
    - [1.2如今生成式AI的特点](#12如今生成式ai的特点)
  - [1.3 Ai Agent](#13-ai-agent)
- [2.运作机制](#2运作机制)
  - [2.1 Generative AI基本原理](#21-generative-ai基本原理)
    - [2.1.1 基本单位](#211-基本单位)
    - [2.1.2 生成策略](#212-生成策略)
    - [2.1.3 如何决定下一个token](#213-如何决定下一个token)
  - [2.2 深度学习（`DeepLearning`）](#22-深度学习deeplearning)
    - [2.2.1 深度学习是什么](#221-深度学习是什么)
    - [2.2.2 机器的‘思考’也是另一种深度](#222-机器的思考也是另一种深度)
    - [2.2.3 每层layer中的运作](#223-每层layer中的运作)
- [3.如何被产生出来](#3如何被产生出来)
  - [3.1 类神经网络组成](#31-类神经网络组成)
    - [3.1.1 架构与参数](#311-架构与参数)
    - [3.1.2 如何找出参数](#312-如何找出参数)
  - [3.2 分类（`Classification`）问题](#32-分类classification问题)
- [4.怎么赋予ai新的能力](#4怎么赋予ai新的能力)
  - [4.1 机器的终身学习（`Life-Long Learning`）时代](#41-机器的终身学习life-long-learning时代)
  
### 1.有什么样的行为
#### 1.1过去生成式ai用处及特点
<img src="https://i-blog.csdnimg.cn/direct/bb96899003f0430da0a42f600a5e5959.png">
特征：给机器输入一个问题（`input`），直接给出答案（`output`），输出可以为多种形式，如图中的文字、图片、视频、音频等.过去各个ai大多专精某个领域.

##### 1.2如今生成式AI的特点
以ChatGPT o1，o3、DeepSeek、Gemini Flash为例，机器展现出“思考”（`reasoning`）的过程。 在得出真正的output之前会进行如人类思考的过程，出演“脑内剧场”，思考多种路径及其走向，展现其对于问题不同角度看法。
#### 1.3 Ai Agent
由于很多任务往往无法一步完成，需细化为多个步骤，未来AI的工作方式将不再局限于一问一答，可执行多个复杂的步骤的AI，我们称其为AI Agent.
- 部分ai具有的“Deep Research”功能，在问问题后会自行上网搜寻，且不是一搜寻便得出结果，其还会再次对自己提出问题，达到“Deep”的效果
<img src="https://i-blog.csdnimg.cn/direct/726a500f6cf047c9845caab8feba6a3e.png">
- ai不仅具备生成功能，还有操纵功能，例如其可以操作鼠标的移动和点击，因而其可以实现如预约等功能
<img src="https://i-blog.csdnimg.cn/direct/1ce316fd69ac4fbeaea9570db1988b7f.png">
- 开发机器学习模型基本步骤：训练一个模型后，根据其表现不断纠正和修改，如此反复.
<img src="https://i-blog.csdnimg.cn/direct/422e5de3d9c7450b88492681ecf2b734.png">

### 2.运作机制
#### 2.1 Generative AI基本原理 
##### 2.1.1 基本单位
生成式人工智能的输入和输出均可以是较复杂的信息，如文字、图片、语音等
- 基本原理：将输入转变为基本单位(`token`)
>这些基本单位必须有限，如汉字的个数有限、构成图片的像素(`pixel`)由RGB构成也有限，声音讯号由取样点构成，同样有限。有限的token能组合出无限的可能 

<img src="https://i-blog.csdnimg.cn/direct/4f413f449aac4ee391cd6dad0f48f260.png">

##### 2.1.2 生成策略
- 根据输入的一串token，按照固定的次序依次生成$y_i$（也就是说，$y_1到y_{i-1}$也都是$y_i$的输入）,输出以终止符结束.
<img src="https://i-blog.csdnimg.cn/direct/8234dc99d30a4ae58e41f635313abd44.png"> 

##### 2.1.3 如何决定下一个token
- 通过函数(`function`)f来构成类神经网络(`neural network`)，其输出为概率分布，再通过某些采样(`sample`)方式输出具体token，因而输入即使是一样的，输出也可能不同
<img src="https://i-blog.csdnimg.cn/direct/6df3458950e84639b6e679a158631ac8.png">

#### 2.2 深度学习（`DeepLearning`）
##### 2.2.1 深度学习是什么
- 类神经网络就是把一个大的function拆解成多个函数（`layer`），每个layer的输入和输出都是一组向量（`vector`），因而类神经网络又叫作深度学习
<img src="https://i-blog.csdnimg.cn/direct/d3400083c2f743ddb26f0abfb2b38ee0.png">
- 深度学习可以把较为复杂的问题简化（以三个个位数相加为不太准确的比喻：三个数字相加可以产生10×10×10种可能，可以把他简化为两遍的两个数字相加，把可能性降低为10×10+19×10种）
<img src="https://i-blog.csdnimg.cn/direct/62eaa4d176b240e1bcaea7758d8d704e.png">

##### 2.2.2 机器的‘思考’也是另一种深度
- “深度不够，长度来凑”（`Testing Time Scaling`）能解决layer层数不够的问题。类神经网络的深度是有限的，但是思考的过程可以是无限的，即使每次输入是一致的，仍能得到较好的结果。
<img src="https://i-blog.csdnimg.cn/direct/1d8c3842032d434b9568da7e6281931c.png">
##### 2.2.3 每层layer中的运作
每层layer中又可细分成多个layer层。layer有两类，一类称作自注意力层（`Self-Attention Layer`），其可考虑全部输入再产生输出。另一类layer只对单个token进行深入思考。具有自注意力层的类神经网络又叫作`Transformer`。

### 3.如何被产生出来
#### 3.1 类神经网络组成
##### 3.1.1 架构与参数
- 类神经网络由架构（`architecture`/`hyperparameter`）和参数（`parameter`）构成，参数数量以billion为单位（7b模型/70b模型），参数**数量**是架构的一部分，参数**数值**须透过训练资料学习。 用$f_\theta$来表示类神经网络的参数
<img src="https://i-blog.csdnimg.cn/direct/b5be1a0b0b1346f3a8cf8cda5e8d42c1.png">
##### 3.1.2 如何找出参数
- 找出参数等同于训练模型，通过训练资料找出能让$f_\theta$最满足训练资料的$\theta$，可理解为$f_\theta$输出为概率分布（`Possibility Distribution`），找出$\theta$让满足训练资料的token的分数值最高
<img src="https://i-blog.csdnimg.cn/direct/53e7299305b5484396c4b41d191fa709.png">

#### 3.2 分类（`Classification`）问题
- 生活中的很多情况都可以看作是分类问题：如信用卡侦测、垃圾邮件侦测、甚至下围棋也是
<img src="https://i-blog.csdnimg.cn/direct/d945ed7c6a6c4c20a4c84071be8faf62.png">
- 生成式ai可看作是一系列分类问题的集合，只是我们给定了其`Prompt`指定了其功能，因而在某种程度上不能够说是全新的技术
<img src="https://i-blog.csdnimg.cn/direct/0dd3c25a716840a2bc988d5b8fd09353.png">

### 4.怎么赋予ai新的能力
#### 4.1 机器的终身学习（`Life-Long Learning`）时代
- 让已经具备基本能力的通用模型担负某些任务不需要复杂技术，只需给其相关知识，这样模型便可读懂指令和知识，按照需求运作。在这种情况下，其参数是固定的，不会因为输入不同而永久改变。
<img src="https://i-blog.csdnimg.cn/direct/97af6efb238e4d39827dca7f3c6581b2.png">
- 若想使机器永久具备新能力，则需通过微调（`Fine-tune`）来改变参数，但若微调不当，则可能造成输出混乱。可以用（`Model Editing`）的方法，修改类神经网络的参数来手动修改参数。
<img src="https://i-blog.csdnimg.cn/direct/fed1fa5be31844eebd8529ce2666b961.png">
