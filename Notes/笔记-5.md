### 05 大型语言模型训练方法：预训练-对齐
***
### 目录
- [05 大型语言模型训练方法：预训练-对齐](#05-大型语言模型训练方法预训练-对齐)
- [目录](#目录)
- [1.训练语言模型的三个阶段](#1训练语言模型的三个阶段)
- [2.Alignment](#2alignment)
  - [2.1 初探Alignment](#21-初探alignment)
  - [2.2 Alignment需要什么资料](#22-alignment需要什么资料)
  - [2.3 Knowledge Distillation](#23-knowledge-distillation)
  - [2.4 Alignment前后差异](#24-alignment前后差异)
  - [2.5 由差异小得出的猜想：Alignment其实很容易？](#25-由差异小得出的猜想alignment其实很容易)
  - [2.6 Self-Alignment](#26-self-alignment)
- [3.如何达成有效的Pretrain？](#3如何达成有效的pretrain)
  - [3.1 初步实验及问题](#31-初步实验及问题)
  - [3.2 如今Pretrain需要的资料量](#32-如今pretrain需要的资料量)
  - [3.3 资料品质的重要性](#33-资料品质的重要性)
  - [3.4 资料选取的广度or深度？](#34-资料选取的广度or深度)
- [4. Alignment的极限](#4-alignment的极限)
  - [4.1 什么资料对Alignment最有帮助？](#41-什么资料对alignment最有帮助)
  - [4.2 RL——Alignment的好方法](#42-rlalignment的好方法)
  - [4.3 Pretrain的后遗症](#43-pretrain的后遗症)
### 1.训练语言模型的三个阶段
- 训练语言模型一般分成三个阶段.第一阶段：`Pre-train`（预训练），第二阶段：`Supervised Fine-tuning(SFT)`（有监督微调）,第三阶段：`RLHF`（基于人类反馈的强化学习）. 把需要人类参与的阶段叫作`Alignment`
<img src="https://i-blog.csdnimg.cn/direct/dbeaf04f3d7947b1b12402a42d02549a.png">

### 2.Alignment
#### 2.1 初探Alignment
- 以LLaMA-2-7b-base模型为例（以base为结尾即只做了pretrain），该模型虽有回答能力，但回答机械且重复.
<img src="https://i-blog.csdnimg.cn/direct/dfa06324c2ee4a59adc1045f5c5db284.png">
  该模型在进行alignment后（LLaMa-2-7b-chat），其回答更加详细、有条理. **看起来**，模型在alignment前后行为差异大.
<img src="https://i-blog.csdnimg.cn/direct/71a634de0a604608ae901c5ed49703fb.png">

#### 2.2 Alignment需要什么资料
- Alignment不需要过多的资料，但必须有质量（Alignment起到画龙点睛的作用，pretrain是龙的主体，而Alignment就是眼睛）
#### 2.3 Knowledge Distillation
- 可以通过`Knowledge Distillation`,对已经进行了完备的Alignment的教师模型进行模仿学习.当然，老师模型的能力有限，资料质量也有良莠不齐的问题，也需要对资料进行清理.
<img src="https://i-blog.csdnimg.cn/direct/f00f5083ff8b44a79d2f1c560362150f.png">
- 问题如何挑选？可以随意摘取一句话的前半段（甚至可以非一问一答的资料）当作问题给老师模型进行续写，把续写出来的内容当作模型给LLM学习. 实验证明，这种方法对于Alignment非常有帮助
<img src="https://i-blog.csdnimg.cn/direct/2a7604c59d42442495599f33dd41024b.png">

#### 2.4 Alignment前后差异
- 为什么看似奇怪的资料能有效地进行Alignment呢？事实上，Aligenment前后模型实际**行为**差异不大.引入如图论文进行解释.定义Alignment后的三个状态：`Unshift`:几率最高的token不变、`Marginal`:该token变为二/三名、`Shifted`:该token不在前三名.
<img src="https://i-blog.csdnimg.cn/direct/c92c118e6c514981b4e8f8923cb917e1.png">
如图可见，三组模型Alignment前后的对比中，Shifted token比例低，即模型实际**行为**差异不大，导致答案差异大的原因是模型文字接龙，有“一步错步步错”现象.图中继续观察发现：三组模型被Shift的token大多都是连接词、未Alignment模型较不易输出结束生成的符号.
<img src="https://i-blog.csdnimg.cn/direct/57ad453f0dbe42ab8326131e57c778ee.png">

#### 2.5 由差异小得出的猜想：Alignment其实很容易？
- 猜想：既然Alignment前后的差异只是某些token的差异，是否可以不进行Fine-tune，只通过手动修改token出现几率来达到Alignment的效果？
- 给模型手动设定三个规则：
    - 1：增加结束符号出现的概率，且输出长度越长越易出现（优化输出不易停止问题）
    - 2：改变某些符号出现概率
    - 3：降低已输出的token的几率（优化重复输出问题）
- 实验结果显示，该base model与instruction model的win rate由2.4%升高至24.4%，效能得到了极大的提升.
<img src="https://i-blog.csdnimg.cn/direct/e2b1ace04d0043538ddc4935189f4ba2.png">

#### 2.6 Self-Alignment
- Self-Alignment原理：给定一个输入，未alignment的模型给出多个输出，给予模型评分机制自行对输出进行评分，再通过评分对原模型做reinforcement learning. 反复这个过程.也能使模型能力提升
<img src="https://i-blog.csdnimg.cn/direct/fcc305747910446197d12b63fe6418af.png">

### 3.如何达成有效的Pretrain？
#### 3.1 初步实验及问题
初步实验步骤如下：
   - 1.给模型提供N个人的资料（每个人资料仅出现一遍）
   - 2.挑选出$\frac{N}{2}$个人相关的问题进行Alignment
   - 3.以剩下$\frac{N}{2}$个人的问题进行测试.
但实验结果出人意料，在pretrain已经有相关资料训练的情况下，模型正确率几乎为0%.
<img src="https://i-blog.csdnimg.cn/direct/a2ae7942b1fd4ebf888e2f007650907d.png">
原因：在同一语义的不同的表达下，模型可能对主体产生误解.如“小明是A，也是B”，模型可能理解成“小明是A”为主语.

- 由此对实验进行改良：在第一步中，N个人的资料提供多种叙述版本，此时模型正确率高达96%.若只对$\frac{N}{10}$个人的资料提供多种版本，同时把这些资料用于Alignment，仍能达到最高80%的正确率.
  
#### 3.2 如今Pretrain需要的资料量
以LLaMA 3和DeepSeek-V3为例，前者用了15T（trillion）个token，后者用了14.8T个token，需要大量资料.可以在Hugging Face推出的FineWeb上获取15T的经清理后的资料
#### 3.3 资料品质的重要性
- 实验如下：将网络上爬取的资料先经过一个Rephrase Model，把网络上文章改写成易读的后再进行训练. 实验结果显示：在同样正确率下，没有改写过的资料较改写过的资料，需要花三倍的资料量.
<img src="https://i-blog.csdnimg.cn/direct/3b50753a936f4c07a84065c005606119.png">

#### 3.4 资料选取的广度or深度？
在算力有限的情况下，一个模型应该尽量用更多**不同**的资料训练，而不是相同资料的重复.图中所示，当模型在看到4次重复的token时，开始与非重复资料的模型产生差距;当看到40次重复的token时，能力几乎不再增长
<img src="https://i-blog.csdnimg.cn/direct/5a205e0a7f8546b983145002c6698f5f.png">

### 4. Alignment的极限
#### 4.1 什么资料对Alignment最有帮助？
将进行Alignment的资料分成四个类型：
  - 1.`Highly Known`：base model不经过Alignment本来就掌握的资料
  - 2.`Maybe Known`：通过正确问法才能答对的资料
  - 3.`Weakly Known`：对答案sample后才有可能答对的资料
  - 4.`Unknown`：不管怎样sample都无法答对的资料  

实验结果显示，选择Maybe Known的资料对模型最有帮助
<img src="https://i-blog.csdnimg.cn/direct/d31c63156fc547c9a07c376344236dad.png">

#### 4.2 RL——Alignment的好方法
强化学习RL（`Reinforcement Learning`）对Alignment最有帮助，其只对模型自身产生答案进行干预，本质上是激发模型潜力，难以学习新技能
<img src="https://i-blog.csdnimg.cn/direct/dc35adff1d6149e9a383cd7e6bd8ca56.png">

#### 4.3 Pretrain的后遗症
若在Pretrain时有不干净的资料，会产生资料对应的参数.而Alignment做的只是改变了激发这些token的weight，难以清除参数，导致其保留在模型内部.
<img src="https://i-blog.csdnimg.cn/direct/801b1ed3faf9458cba04829a07efee30.png">